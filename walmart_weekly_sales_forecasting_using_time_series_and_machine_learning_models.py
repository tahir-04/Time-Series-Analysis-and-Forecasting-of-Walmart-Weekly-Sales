# -*- coding: utf-8 -*-
"""Walmart Weekly Sales Forecasting Using Time Series and Machine Learning Models

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JuLETR1FSJVt2T8vtdOhGVPaubrjw978
"""

import pandas as pd

# Load CSV files instead of Excel
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")
features = pd.read_csv("features.csv")
stores = pd.read_csv("stores.csv")

print(train.head())
print(features.head())
print(stores.head())

print(train.isnull().sum())
print(features.isnull().sum())
print(stores.isnull().sum())

features.fillna(method='ffill', inplace=True)  # Or use mean/median imputation

# Merge train set
train_merged = train.merge(stores, on='Store') \
                    .merge(features, on=['Store', 'Date', 'IsHoliday'])

# Merge test set (for future predictions)
test_merged = test.merge(stores, on='Store') \
                  .merge(features, on=['Store', 'Date', 'IsHoliday'])

train_merged['Date'] = pd.to_datetime(train_merged['Date'])
train_merged['Year'] = train_merged['Date'].dt.year
train_merged['Month'] = train_merged['Date'].dt.month
train_merged['Week'] = train_merged['Date'].dt.isocalendar().week
train_merged['DayOfWeek'] = train_merged['Date'].dt.dayofweek
train_merged['IsWeekend'] = train_merged['DayOfWeek'].isin([5,6]).astype(int)

train_merged['Type'] = train_merged['Type'].map({'A': 0, 'B': 1, 'C': 2})

import seaborn as sns
import matplotlib.pyplot as plt

# Sales trend over time
total_sales = train_merged.groupby('Date')['Weekly_Sales'].sum()
total_sales.plot(title='Weekly Sales Over Time', figsize=(14,6))
plt.show()

store_1 = train_merged[train_merged['Store'] == 1]
store_sales = store_1.groupby('Date')['Weekly_Sales'].sum().asfreq('W').fillna(method='ffill')

from statsmodels.tsa.statespace.sarimax import SARIMAX
model = SARIMAX(store_sales, order=(1,1,1), seasonal_order=(1,1,1,52))
results = model.fit()

forecast = results.forecast(steps=30)

from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor

X = train_merged.drop(['Weekly_Sales', 'Date'], axis=1)
y = train_merged['Weekly_Sales']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)

model = XGBRegressor()
model.fit(X_train, y_train)
y_pred = model.predict(X_val)

from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

mae = mean_absolute_error(y_val, y_pred)
rmse = np.sqrt(mean_squared_error(y_val, y_pred))
print(f"MAE: {mae}, RMSE: {rmse}")

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Make sure your Date column is in datetime format
train['Date'] = pd.to_datetime(train['Date'])
features['Date'] = pd.to_datetime(features['Date'])

# Merge everything
merged = train.merge(stores, on='Store') \
              .merge(features, on=['Store', 'Date', 'IsHoliday'])

# Add more date features
merged['Year'] = merged['Date'].dt.year
merged['Month'] = merged['Date'].dt.month
merged['Week'] = merged['Date'].dt.isocalendar().week
merged['DayOfWeek'] = merged['Date'].dt.dayofweek

plt.figure(figsize=(14,6))
merged.groupby('Date')['Weekly_Sales'].sum().plot()
plt.title("Total Weekly Sales Over Time")
plt.xlabel("Date")
plt.ylabel("Sales ($)")
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12,5))
store_sales = merged.groupby('Store')['Weekly_Sales'].sum().sort_values(ascending=False)
sns.barplot(x=store_sales.index, y=store_sales.values, palette="viridis")
plt.title("Total Sales by Store")
plt.xlabel("Store")
plt.ylabel("Total Sales ($)")
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10,6))
sns.boxplot(x='Month', y='Weekly_Sales', data=merged)
plt.title("Monthly Sales Distribution")
plt.xlabel("Month")
plt.ylabel("Sales ($)")
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(8,5))
sns.boxplot(x='Type', y='Weekly_Sales', data=merged)
plt.title("Store Type vs Weekly Sales")
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(6,4))
sns.boxplot(x='IsHoliday', y='Weekly_Sales', data=merged)
plt.title("Holiday vs Non-Holiday Sales")
plt.xticks([0, 1], ['Non-Holiday', 'Holiday'])
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np

# Assume you have: y_val (true values) and y_pred (model predictions)
plt.figure(figsize=(14,6))
plt.plot(np.arange(len(y_val)), y_val, label="Actual", alpha=0.7)
plt.plot(np.arange(len(y_pred)), y_pred, label="Predicted", alpha=0.7)
plt.title("Actual vs Predicted Sales")
plt.xlabel("Sample")
plt.ylabel("Weekly Sales")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()





pip install streamlit





import matplotlib.pyplot as plt

# Calculate metrics
from sklearn.metrics import mean_absolute_error, mean_squared_error
mae = mean_absolute_error(y_val, y_pred)
rmse = np.sqrt(mean_squared_error(y_val, y_pred))
mape = np.mean(np.abs((y_val - y_pred) / y_val)) * 100

# Visualization
metrics = {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}
names = list(metrics.keys())
values = list(metrics.values())

plt.figure(figsize=(8,5))
bars = plt.bar(names, values, color=['#36a2eb', '#ff6384', '#ffcd56'])
plt.title("ðŸ“Š Model Performance Metrics")
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.05*yval, f'{yval:.2f}', ha='center', va='bottom')
plt.ylabel("Metric Value")
plt.tight_layout()
plt.show()